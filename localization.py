# UI í…ìŠ¤íŠ¸ í˜„ì§€í™” / UI Text Localization
STRINGS = {
    'ko': {
        "select_language": "ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš” (1: í•œêµ­ì–´, 2: English): ",
        "invalid_input": "ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. 1 ë˜ëŠ” 2ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
        "mode_selected": "\n'{lang_upper}' ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ íŒŒì¼: '{prompt_filepath}'",
        "fetching_models": "ğŸ¤– OpenRouterì—ì„œ ìµœì‹  ëª¨ë¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...",
        "fetching_models_done": "âœ… ëª¨ë¸ ì •ë³´ ë¡œë“œ ì™„ë£Œ.",
        "fetching_models_failed": "âš ï¸ ëª¨ë¸ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨. ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ê³„ì†í•©ë‹ˆë‹¤.",
        "error_no_models": "ì˜¤ë¥˜: '{filepath}'ì— ì‚¬ìš©í•  ëª¨ë¸ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŒ.",
        "error_file_not_found": "ì˜¤ë¥˜: '{filepath}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ.",
        "error_no_headers": "ì˜¤ë¥˜: '{filepath}'ì—ì„œ '## ì„¹ì…˜ëª… ##' í˜•ì‹ì˜ í—¤ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ.",
        "error_no_project_name": "ì˜¤ë¥˜: í”„ë¡¬í”„íŠ¸ íŒŒì¼ì— '## project name ##' ì„¹ì…˜ì´ ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.",
        "error_no_system_prompt":"ì˜¤ë¥˜: í”„ë¡¬í”„íŠ¸ íŒŒì¼ì— '## system prompt ##' ì„¹ì…˜ì´ ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.",
        "error_no_api_key": "ì˜¤ë¥˜: .env íŒŒì¼ì— OPENROUTER_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŒ.",
        "research_start": "ğŸš€ í”„ë¡œì íŠ¸ '{project_name}' ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤. (ë°±ê·¸ë¼ìš´ë“œ ë¡œê¹… ì „ìš©)",
        "output_folder_info": "ğŸ“‚ ê²°ê³¼ëŠ” '{output_dir}' í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.",
        "live_log_info": "ğŸ‘ï¸  ì‹¤ì‹œê°„ ë¡œê·¸ëŠ” `python view_log.py`ë¡œ í™•ì¸í•˜ì„¸ìš”.",
        "models_in_use": "ğŸ¤– ì‚¬ìš©í•  ëª¨ë¸: {models_list}",
        "collaboration_disabled": "ğŸ¤ AI í˜‘ì—… ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "prompt_execution": "â–¶ï¸ í”„ë¡¬í”„íŠ¸ {prompt_id}/{total_prompts} ì‹¤í–‰: {prompt_name}",
        "reasoning_activated": "   âœ¨ Reasoning ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "request_start": "   (ì´ {num_models}ê°œ ëª¨ë¸ì— ë™ì‹œ ìš”ì²­ ë° ë¡œê¹… ì‹œì‘...)",
        "log_prompt_header": "\n\n{divider} í”„ë¡¬í”„íŠ¸ {prompt_id} ({prompt_name}) {divider}\n\n",
        "log_reasoning_header": "\n--- [ìƒê° ê³¼ì •] ---\n",
        "log_error_header": "\n\n--- ì˜¤ë¥˜ ---\n{error_message}\n",
        "log_error_message": "ì˜¤ë¥˜ ë°œìƒ: {e}",
        "task_completed": "âœ… '{nick}' ì‘ì—… ì™„ë£Œ.",
        "task_failed": "âŒ '{nick}' ì‘ì—… ì‹¤íŒ¨.",
        "task_error": "âŒ '{model_nickname}' ì‘ì—… ì²˜ë¦¬ ì¤‘ ìµœì¢… ì˜¤ë¥˜: {e}",
        "prompt_finished": "\n--- í”„ë¡¬í”„íŠ¸ {prompt_id} ëª¨ë“  ì‘ì—… ì™„ë£Œ ---",
        "all_finished": "âœ… ëª¨ë“  ì‘ì—… ê³¼ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
        "select_bot": "\nì–´ë–¤ ì‘ì—…ì„ ì‹œì‘í• ê¹Œìš”?",
        "bot_option_research": "[1] ë¦¬ì„œì¹˜ ë´‡ ì‹¤í–‰ (ê¸°ë³¸ê°’)",
        "bot_option_custom": "[2] ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì§€ì •",
        "enter_prompt_filename": "prompts/ í´ë” ì•ˆì— ìˆëŠ” íŒŒì¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: my_custom_task.md): ",
    },
    'en': {
        "select_language": "Select language (1: í•œêµ­ì–´, 2: English): ",
        "invalid_input": "Invalid input. Please enter 1 or 2.",
        "mode_selected": "\nRunning in '{lang_upper}' mode. Prompt file: '{prompt_filepath}'",
        "fetching_models": "ğŸ¤– Fetching latest model information from OpenRouter...",
        "fetching_models_done": "âœ… Model information loaded successfully.",
        "fetching_models_failed": "âš ï¸ Failed to fetch model information. Proceeding with default settings.",
        "error_no_models": "Error: No models specified in '{filepath}'.",
        "error_file_not_found": "Error: File not found at '{filepath}'.",
        "error_no_headers": "Error: Could not find headers in '## Section ##' format in '{filepath}'.",
        "error_no_project_name": "Error: The prompt file must contain a '## project name ##' section.",
        "error_no_system_prompt": "Error: The prompt file must contain a '## system prompt ##' section.",
        "error_no_api_key": "Error: OPENROUTER_API_KEY is not set in the .env file.",
        "research_start": "ğŸš€ Starting task for project '{project_name}'. (Background Logging Only)",
        "output_folder_info": "ğŸ“‚ Results will be saved in the '{output_dir}' folder.",
        "live_log_info": "ğŸ‘ï¸  Check live logs with `python view_log.py`.",
        "models_in_use": "ğŸ¤– Models in use: {models_list}",
        "collaboration_disabled": "ğŸ¤ AI collaboration is disabled.",
        "prompt_execution": "â–¶ï¸ Executing Prompt {prompt_id}/{total_prompts}: {prompt_name}",
        "reasoning_activated": "   âœ¨ Reasoning mode activated.",
        "request_start": "   (Starting concurrent requests and logging for {num_models} models...)",
        "log_prompt_header": "\n\n{divider} PROMPT {prompt_id} ({prompt_name}) {divider}\n\n",
        "log_reasoning_header": "\n--- [REASONING PROCESS] ---\n",
        "log_error_header": "\n\n--- ERROR ---\n{error_message}\n",
        "log_error_message": "Error occurred: {e}",
        "task_completed": "âœ… Task for '{nick}' completed.",
        "task_failed": "âŒ Task for '{nick}' failed.",
        "task_error": "âŒ Final error while processing task for '{model_nickname}': {e}",
        "prompt_finished": "\n--- All tasks for Prompt {prompt_id} are complete ---",
        "all_finished": "âœ… All processes have been completed.",
        "select_bot": "\nWhich task would you like to start?",
        "bot_option_research": "[1] Run Research Bot (Default)",
        "bot_option_custom": "[2] Specify a different prompt file",
        "enter_prompt_filename": "Enter the filename located in the prompts/ folder (e.g., my_custom_task.md): ",
    }
}
