2025-07-18 10:22:10
ì•Œê² ìŠµë‹ˆë‹¤. ê¸°ìˆ  ë¬¸ì„œ ì‘ì„±ê°€ë¡œì„œ, ì‚¬ìš©ìì™€ ê°œë°œìë¥¼ ìœ„í•œ ëª…í™•í•˜ê³  ìƒì„¸í•œ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.

---
### **í•œê¸€ ë²„ì „ (Korean Version)**
---

### `README.md`

# AI-Forge: AI ì›Œí¬í”Œë¡œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°

**ë‹¤ì–‘í•œ AI ëª¨ë¸ì„ ë³‘ë ¬ ì‹¤í–‰í•˜ê³ , í”„ë¡¬í”„íŠ¸ ì„¤ê³„ë§Œìœ¼ë¡œ AI í˜‘ì—…, ì½”ë“œ ê°œì„ , ë©€í‹°ëª¨ë‹¬ ë¶„ì„ì„ ìë™í™”í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.**

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

-   **ë‹¤ì¤‘ AI ë³‘ë ¬ ì²˜ë¦¬**: `ai_models.txt`ì— ëª…ì‹œëœ ëª¨ë“  AI ëª¨ë¸ì— ì‘ì—…ì„ ë™ì‹œì— ë¶„ì‚°í•˜ì—¬ ì²˜ë¦¬ ì†ë„ë¥¼ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.
-   **í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì›Œí¬í”Œë¡œ**: ì½”ë“œë¥¼ ìˆ˜ì •í•  í•„ìš” ì—†ì´, `prompts/` í´ë” ì•ˆì˜ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ í•˜ë‚˜ë¡œ ì „ì²´ ì‘ì—… íë¦„(ë¶„ì„, í˜‘ì—…, ì¶œë ¥ í˜•ì‹ ë“±)ì„ ììœ ë¡­ê²Œ ì„¤ê³„í•˜ê³  ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
-   **êµ¬ì¡°ì  ë°ì´í„° í˜‘ì—…**: AIê°€ ìƒì„±í•œ JSON í˜•ì‹ì˜ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ë‹¤ìŒ ë‹¨ê³„ì˜ AIê°€ ì°¸ê³ í•˜ì—¬, ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì „ë‹¬ ë°©ì‹ë³´ë‹¤ í›¨ì”¬ ì•ˆì •ì ì´ê³  ì •í™•í•œ í˜‘ì—…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. (`#other_ai_info` íƒœê·¸ í™œìš©)
-   **ë©€í‹°ëª¨ë‹¬ ì…ë ¥ ì§€ì›**: í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë‚´ì—ì„œ `#img`, `#pdf`, `#code` íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€, PDF, ì½”ë“œ íŒŒì¼ì„ AIì—ê²Œ ì§ì ‘ ì „ë‹¬í•˜ê³  ë¶„ì„ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
-   **ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§**: ë©”ì¸ í”„ë¡œì„¸ìŠ¤ì™€ ë³„ë„ë¡œ, ê° ëª¨ë¸ì˜ ì‹¤ì‹œê°„ ì‘ì—… ê³¼ì •(`reasoning` í¬í•¨)ì„ ë¡œê·¸ íŒŒì¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ’¾ ì„¤ì¹˜ ê°€ì´ë“œ (Installation)

### 1. ì €ì¥ì†Œ ë³µì œ

```bash
git clone https://github.com/Your-Username/AI-Forge.git
cd AI-Forge
```

### 2. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env.example` íŒŒì¼ì„ ë³µì‚¬í•˜ì—¬ `.env` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

```bash
cp .env.example .env
```

ìƒì„±ëœ `.env` íŒŒì¼ì„ ì—´ê³ , OpenRouter API í‚¤ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.

```sh
# .env
OPENROUTER_API_KEY="sk-or-v1-..."
```

### 4. AI ëª¨ë¸ ëª©ë¡ ì„¤ì •

`ai_models.txt` íŒŒì¼ì„ ì—´ê³ , ì‚¬ìš©í•˜ê³  ì‹¶ì€ AI ëª¨ë¸ì˜ IDë¥¼ í•œ ì¤„ì— í•˜ë‚˜ì”© ì…ë ¥í•©ë‹ˆë‹¤. (ì˜ˆ: `google/gemini-flash-1.5`)

## ğŸš€ ì‚¬ìš©ë²• ë° ì˜ˆì‹œ (Usage & Example)

### ê¸°ë³¸ ì‹¤í–‰

í„°ë¯¸ë„ì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´, ëŒ€í™”í˜• ëª¨ë“œë¥¼ í†µí•´ ì–¸ì–´ì™€ ì‹¤í–‰í•  í”„ë¡¬í”„íŠ¸ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
python main.py
```

### íŠ¹ì • í”„ë¡¬í”„íŠ¸ ì§€ì • ì‹¤í–‰

`--lang`ê³¼ `--prompt` ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì¦‰ì‹œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# research_ko.md í”„ë¡¬í”„íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ì‹¤í–‰
python main.py --lang ko --prompt research.md
```

### í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì„¤ê³„ (`prompts/research.md` ì˜ˆì‹œ)

ì´ í”„ë ˆì„ì›Œí¬ì˜ ëª¨ë“  ë™ì‘ì€ `prompts/` í´ë” ì•ˆì˜ `.md` íŒŒì¼ë¡œ ì œì–´ë©ë‹ˆë‹¤. ëª¨ë“  í”„ë¡¬í”„íŠ¸ íŒŒì¼ì€ ì•„ë˜ì™€ ê°™ì€ ê·œì¹™ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.

-   **`## project name ##`**: ì‘ì—…ì˜ ê³ ìœ  ì´ë¦„. ê²°ê³¼ë¬¼ì´ ì €ì¥ë  í´ë”ëª…ìœ¼ë¡œ ì‚¬ìš©ë˜ë¯€ë¡œ **ë°˜ë“œì‹œ íŒŒì¼ ìµœìƒë‹¨ì— ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.**
-   **`## system prompt ##`**: ëª¨ë“  AI ëª¨ë¸ì—ê²Œ ê³µí†µì ìœ¼ë¡œ ì ìš©ë  ì‹œìŠ¤í…œ ì§€ì¹¨(ì—­í• , í†¤ì•¤ë§¤ë„ˆ ë“±)ì…ë‹ˆë‹¤.
-   **`## promptN: [ì„¤ëª…] ##`**: ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë  ì‘ì—… ë‹¨ê³„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. `N`ì€ ì‹¤í–‰ ìˆœì„œë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìˆ«ìì…ë‹ˆë‹¤.

```markdown
## project name ##
My Awesome Project

## system prompt ##
ë‹¹ì‹ ì€ ìµœê³ ì˜ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

## prompt1: [1ë‹¨ê³„: ì •ë³´ ìˆ˜ì§‘] ##
# reasoning
# img: path/to/your/image.jpg
# pdf: path/to/your/document.pdf
# code: path/to/your/code.py
[í”„ë¡¬í”„íŠ¸ ìƒì„¸ ì§€ì‹œì‚¬í•­...]

## prompt2: [2ë‹¨ê³„: êµì°¨ ê²€ì¦] ##
# other_ai_info
[í”„ë¡¬í”„íŠ¸ ìƒì„¸ ì§€ì‹œì‚¬í•­...]
```

#### **ì˜µì…˜ íƒœê·¸ ìƒì„¸ ì„¤ëª…**

-   `# reasoning`: AIì˜ ìƒê° ê³¼ì •ì„ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡í•˜ì—¬ ë””ë²„ê¹…ì„ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.
-   `# other_ai_info`: ì´ì „ ë‹¨ê³„(`prompt1`)ì—ì„œ ë‹¤ë¥¸ AIë“¤ì´ ìƒì„±í•œ ë‹µë³€ì„ í˜„ì¬ AI(`prompt2`)ê°€ ì°¸ê³ í•˜ë„ë¡ í•©ë‹ˆë‹¤.
-   `# img: [ê²½ë¡œ]`, `# pdf: [ê²½ë¡œ]`, `# code: [ê²½ë¡œ]`: í•´ë‹¹ ê²½ë¡œì˜ íŒŒì¼ì„ í”„ë¡¬í”„íŠ¸ì— ì²¨ë¶€í•©ë‹ˆë‹¤. ë¡œì»¬ ê²½ë¡œ ë° URLì„ ì§€ì›í•©ë‹ˆë‹¤.

## ğŸ› ï¸ ì˜ì¡´ì„± ë° ìš”êµ¬ì‚¬í•­

-   Python 3.8 ì´ìƒ
-   ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬: `openai`, `aiohttp`, `python-dotenv`, `tenacity` (ìì„¸í•œ ë‚´ìš©ì€ `requirements.txt` ì°¸ê³ )

## â“ ë¬¸ì œ í•´ê²° (FAQ)

-   **Q: `OPENROUTER_API_KEY not found` ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.**
    -   A: í”„ë¡œì íŠ¸ ìµœìƒìœ„ ë””ë ‰í† ë¦¬ì— `.env` íŒŒì¼ì´ ìˆëŠ”ì§€, íŒŒì¼ ë‚´ì— `OPENROUTER_API_KEY`ê°€ ì˜¬ë°”ë¥´ê²Œ ì…ë ¥ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.
-   **Q: `File not found` ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©° í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì§€ ëª»í•©ë‹ˆë‹¤.**
    -   A: ì‹¤í–‰í•˜ë ¤ëŠ” í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ `prompts/` ë””ë ‰í† ë¦¬ ì•ˆì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.
-   **Q: AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í•˜ê±°ë‚˜ ì˜¤ë¥˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.**
    -   A: `ai_models.txt`ì— ì…ë ¥í•œ ëª¨ë¸ IDê°€ ì˜¬ë°”ë¥¸ì§€, í•´ë‹¹ ëª¨ë¸ì´ OpenRouterì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.

---

### `DEV.md`

# AI-Forge ê°œë°œì ë¬¸ì„œ

ì´ ë¬¸ì„œëŠ” AI-Forgeì˜ ì•„í‚¤í…ì²˜, ì„¤ê³„ ê²°ì •, ê·¸ë¦¬ê³  í–¥í›„ í™•ì¥ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## 1. ì•„í‚¤í…ì²˜ ê°œìš”

AI-ForgeëŠ” **ê´€ì‹¬ì‚¬ ë¶„ë¦¬(SoC)** ì›ì¹™ì— ë”°ë¼ ì„¤ê³„ëœ ëª¨ë“ˆí˜• ì•„í‚¤í…ì²˜ë¥¼ ì±„íƒí–ˆìŠµë‹ˆë‹¤. ê° ì»´í¬ë„ŒíŠ¸ëŠ” ëª…í™•í•œ ë‹¨ì¼ ì±…ì„ì„ ê°€ì§€ë©°(SRP), ì´ë¥¼ í†µí•´ ì‹œìŠ¤í…œì˜ ì•ˆì •ì„±, í…ŒìŠ¤íŠ¸ ìš©ì´ì„±, í™•ì¥ì„±ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.

-   **ì„¤ì •(Config)ê³¼ ì‹¤í–‰ ë¬¸ë§¥(Context)ì˜ ë¶„ë¦¬**:
    -   `Config`: ì‹¤í–‰ ì „ ê³ ì •ë˜ëŠ” ë¶ˆë³€ ì„¤ì • (API í‚¤, ëª¨ë¸ ëª©ë¡ ë“±)
    -   `ProjectContext`: ì›Œí¬í”Œë¡œ ì‹¤í–‰ ì¤‘ ìƒì„±ë˜ëŠ” ê°€ë³€ ìƒíƒœ (í”„ë¡œì íŠ¸ ì´ë¦„, ì¶œë ¥ ê²½ë¡œ ë“±)
-   **ì—”ì§„ê³¼ ì„œë¹„ìŠ¤ì˜ ë¶„ë¦¬**:
    -   `WorkflowEngine`: ì „ì²´ ì‘ì—… íë¦„ì„ ì§€íœ˜í•˜ëŠ” ì¤‘ì•™ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°.
    -   `Services`: íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë…ë¦½ì ì¸ ì„œë¹„ìŠ¤ë“¤ (API í†µì‹ , íŒŒì¼ ì²˜ë¦¬, ê²°ê³¼ ì €ì¥ ë“±).

  <!-- ì‹¤ì œ ë‹¤ì´ì–´ê·¸ë¨ URLë¡œ êµì²´ í•„ìš” -->

## 2. ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ëª…

```
.
â”œâ”€â”€ config/       # í™˜ê²½ ì„¤ì • ë° ìƒìˆ˜ ê´€ë¦¬
â”œâ”€â”€ core/         # ì• í”Œë¦¬ì¼€ì´ì…˜ í•µì‹¬ ë¡œì§ (ì—”ì§„, ë°ì´í„° ëª¨ë¸)
â”œâ”€â”€ services/     # ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ë™ ë° íŠ¹ì • ìœ í‹¸ë¦¬í‹° ê¸°ëŠ¥
â”œâ”€â”€ utils/        # ë¡œê¹… ë“± ë²”ìš© ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ prompts/      # ì›Œí¬í”Œë¡œë¥¼ ì •ì˜í•˜ëŠ” .md íŒŒì¼ ì €ì¥ì†Œ
â””â”€â”€ projects/     # AIê°€ ìƒì„±í•œ ê²°ê³¼ë¬¼ì´ ì €ì¥ë˜ëŠ” ê³³
```

## 3. í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ìƒì„¸

### `core/engine.py` - WorkflowEngine

-   **ì—­í• **: ì „ì²´ ì›Œí¬í”Œë¡œì˜ ì‹¤í–‰ì„ ì´ê´„í•˜ëŠ” ì¤‘ì•™ ê´€ì œíƒ‘.
-   **ì£¼ìš” ì±…ì„**:
    -   ì„¤ì • ë° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”.
    -   í”„ë¡¬í”„íŠ¸ íŒŒì¼ íŒŒì‹± ë° ì‹¤í–‰ ìˆœì„œ ê´€ë¦¬.
    -   ê° AI í´ë¼ì´ì–¸íŠ¸ì— ëŒ€í•œ ë³‘ë ¬ ì‘ì—… ìƒì„± ë° ì‹¤í–‰.
    -   ì‹¤í–‰ ê²°ê³¼ ì·¨í•© ë° ë‹¤ìŒ ë‹¨ê³„ë¡œì˜ ì „ë‹¬.
-   **ì½”ë“œ ìŠ¤ë‹ˆí«**:
    ```python
    # core/engine.py
    class WorkflowEngine:
        async def run(self):
            await self._initialize_project()
            self._print_startup_info()
            await self._execute_workflow()
            self._print_completion_info()

        async def _execute_single_prompt(self, prompt: Prompt, is_last: bool):
            tasks = [
                self._process_model_task(client, prompt, is_last)
                for client in self.ai_clients.values()
            ]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            # ... ê²°ê³¼ ì²˜ë¦¬
    ```

### `services/ai_client.py` - AIModelClient

-   **ì—­í• **: ë‹¨ì¼ AI ëª¨ë¸ê³¼ OpenRouter API ê°„ì˜ í†µì‹ ì„ ì „ë‹´.
-   **ì£¼ìš” ì±…ì„**:
    -   API ìš”ì²­ ë©”ì‹œì§€ ìƒì„± (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, íˆìŠ¤í† ë¦¬ í¬í•¨).
    -   API ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬.
    -   ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬.
-   **ì½”ë“œ ìŠ¤ë‹ˆí«**:
    ```python
    # services/ai_client.py
    class AIModelClient:
        async def get_response_stream(self, content: Any, use_reasoning: bool) -> AsyncGenerator[str, None]:
            # ... API ìš”ì²­ ë° ìŠ¤íŠ¸ë¦¼ ë°˜í™˜
    ```

### `services/result_handler.py` - ResultHandler

-   **ì—­í• **: ëª¨ë“  íŒŒì¼ ì…ì¶œë ¥(I/O) ì‘ì—…ì„ ì²˜ë¦¬.
-   **ì£¼ìš” ì±…ì„**:
    -   ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± ë° ì •ë¦¬.
    -   ìµœì¢… ë° ì¤‘ê°„ ê²°ê³¼ íŒŒì¼ ì €ì¥.
    -   ì‹¤ì‹œê°„ ë¡œê·¸ íŒŒì¼ ìƒì„± ë° ë‚´ìš© ì¶”ê°€.
-   **ì½”ë“œ ìŠ¤ë‹ˆí«**:
    ```python
    # services/result_handler.py
    class ResultHandler:
        def save_result(self, prompt_id: int, response: ModelResponse, is_final: bool):
            # ... ê²°ê³¼ íŒŒì¼ ì €ì¥ ë¡œì§
        
        def log_stream_chunk(self, model_nickname: str, chunk: str):
            # ... ë¡œê·¸ íŒŒì¼ì— ìŠ¤íŠ¸ë¦¼ ì²­í¬ ì¶”ê°€
    ```

## 4. ì„¤ê³„ ê²°ì • ë° íŠ¸ë ˆì´ë“œì˜¤í”„

-   **ì™œ ì´ êµ¬ì¡°ë¥¼ ì„ íƒí–ˆëŠ”ê°€?**
    -   ì´ˆê¸° ë²„ì „ì€ `Orchestrator` í´ë˜ìŠ¤ í•˜ë‚˜ì— ë„ˆë¬´ ë§ì€ ì±…ì„(API í†µì‹ , íŒŒì¼ I/O, ìƒíƒœ ê´€ë¦¬)ì´ ì§‘ì¤‘ë˜ì–´ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” **ë†’ì€ ê²°í•©ë„(High Coupling)**ì™€ **ë‚®ì€ ì‘ì§‘ë„(Low Cohesion)**ë¥¼ ìœ ë°œí•˜ì—¬ ì‘ì€ ë³€ê²½ë„ ì‹œìŠ¤í…œ ì „ì²´ì— ì˜í–¥ì„ ë¯¸ì¹  ìœ„í—˜ì´ ì»¸ìŠµë‹ˆë‹¤.
    -   ë¦¬íŒ©í† ë§ëœ í˜„ì¬ êµ¬ì¡°ëŠ” ê° í´ë˜ìŠ¤ê°€ í•˜ë‚˜ì˜ ëª…í™•í•œ ì±…ì„ì„ ê°–ë„ë¡ ë¶„ë¦¬í•˜ì—¬ **ì•ˆì •ì„±**ê³¼ **ìœ ì§€ë³´ìˆ˜ì„±**ì„ ê·¹ëŒ€í™”í–ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, `AIModelClient`ëŠ” ì´ì œ API í†µì‹ ë§Œ ì‹ ê²½ ì“°ë©´ ë˜ë¯€ë¡œ, íŒŒì¼ ì €ì¥ ë°©ì‹ì´ ë³€ê²½ë˜ì–´ë„ `AIModelClient` ì½”ë“œëŠ” ìˆ˜ì •í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.

-   **ê³ ë ¤í–ˆë˜ ëŒ€ì•ˆë“¤**:
    -   **ë‹¨ì¼ `Orchestrator` í´ë˜ìŠ¤ ìœ ì§€**: êµ¬í˜„ì´ ë¹ ë¥´ì§€ë§Œ ì¥ê¸°ì ìœ¼ë¡œ ìœ ì§€ë³´ìˆ˜ ë¹„ìš©ì´ ê¸‰ì¦í•˜ê³  ë²„ê·¸ ë°œìƒ ê°€ëŠ¥ì„±ì´ ë†’ì•„ ê¸°ê°í–ˆìŠµë‹ˆë‹¤.
    -   **Circuit Breaker íŒ¨í„´ ë„ì…**: API ì•ˆì •ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ê³ ë ¤í–ˆìœ¼ë‚˜, í˜„ì¬ `tenacity` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•œ ì¬ì‹œë„(Retry) ë¡œì§ë§Œìœ¼ë¡œë„ ì¶©ë¶„í•˜ë‹¤ê³  íŒë‹¨í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì˜¤ë²„ì—”ì§€ë‹ˆì–´ë§ì„ í”¼í•˜ê¸° ìœ„í•œ ê²°ì •ì…ë‹ˆë‹¤.

-   **í•µì‹¬ ê²°ì •: êµ¬ì¡°ì  ë°ì´í„° íŒŒì´í”„ë¼ì¸**
    -   AI ê°„ í˜‘ì—… ì‹œ, ë‹¨ìˆœ í…ìŠ¤íŠ¸ ëŒ€ì‹  `PromptResult` ë°ì´í„° í´ë˜ìŠ¤ë¥¼ í†µí•´ êµ¬ì¡°í™”ëœ JSON ë°ì´í„°ë¥¼ ì „ë‹¬í•˜ë„ë¡ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” AIê°€ ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ì˜¤í•´ì„í•  ê°€ëŠ¥ì„±ì„ í¬ê²Œ ì¤„ì—¬, ì „ì²´ ì›Œí¬í”Œë¡œì˜ **ì•ˆì •ì„±**ì„ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ëŠ” í•µì‹¬ì ì¸ ì„¤ê³„ ê²°ì •ì…ë‹ˆë‹¤.

## 5. ë¦¬íŒ©í† ë§ íˆìŠ¤í† ë¦¬

-   **ì´ˆê¸° ë²„ì „**: ë‹¨ì¼ `Orchestrator` í´ë˜ìŠ¤ê°€ ëŒ€ë¶€ë¶„ì˜ ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” ëª¨ë†€ë¦¬ì‹ êµ¬ì¡°.
-   **1ì°¨ ë¦¬íŒ©í† ë§ (ì±…ì„ ë¶„ë¦¬)**: `Orchestrator`ì˜ ì±…ì„ì„ `WorkflowEngine`, `ResultHandler`, `ProjectContext`ë¡œ ë¶„ë¦¬í•˜ì—¬ SRP(ë‹¨ì¼ ì±…ì„ ì›ì¹™)ë¥¼ ì ìš©.
-   **2ì°¨ ë¦¬íŒ©í† ë§ (ë°ì´í„° íŒŒì´í”„ë¼ì¸ ê°•í™”)**: `PromptResult` ëª¨ë¸ì„ ë„ì…í•˜ì—¬ AI ê°„ í˜‘ì—… ì‹œ JSON ë°ì´í„°ë¥¼ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ê°œì„ .

## 6. ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬

-   `openai`: OpenRouterì˜ APIì™€ í†µì‹ í•˜ê¸° ìœ„í•œ í´ë¼ì´ì–¸íŠ¸. (ëŒ€ì²´: `httpx` ë“±ì„ ì´ìš©í•œ ì§ì ‘ êµ¬í˜„)
-   `aiohttp`: ëª¨ë¸ ë©”íƒ€ë°ì´í„°ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ” ë° ì‚¬ìš©.
-   `python-dotenv`: `.env` íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œ.
-   `tenacity`: API ìš”ì²­ ì‹¤íŒ¨ ì‹œ ì§€ìˆ˜ ë°±ì˜¤í”„(exponential backoff)ë¥¼ ì ìš©í•œ ì¬ì‹œë„ë¥¼ ê°„í¸í•˜ê²Œ êµ¬í˜„.

## 7. í–¥í›„ í™•ì¥ ê°€ì´ë“œ

-   **ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ ì¶”ê°€ (ì˜ˆ: Slack ì•Œë¦¼)**
    1.  `services/notification_service.py` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
    2.  `WorkflowEngine`ì˜ `run` ë©”ì„œë“œ ë§ˆì§€ë§‰ì— ì•Œë¦¼ ì„œë¹„ìŠ¤ í˜¸ì¶œ ë¡œì§ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
-   **ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ëª…ë ¹ì–´ ì¶”ê°€ (ì˜ˆ: `#db_query`)**
    1.  `config/constants.py`ì˜ `FILE_COMMANDS` ë”•ì…”ë„ˆë¦¬ì— ìƒˆ ëª…ë ¹ì–´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    2.  `services/prompt_parser.py`ì˜ `_extract_attachments` ë©”ì„œë“œì— ê´€ë ¨ ë¡œì§ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    3.  `services/file_handler.py`ì— í•´ë‹¹ ëª…ë ¹ì–´ë¥¼ ì²˜ë¦¬í•  `_handle_db_query`ì™€ ê°™ì€ ë©”ì„œë“œë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

---
### **ì˜ë¬¸ ë²„ì „ (English Version)**
---

### `README.md`

# AI-Forge: AI Workflow Orchestrator

**A framework that runs various AI models in parallel and automates AI collaboration, code improvement, and multimodal analysis, all through simple prompt design.**

## âœ¨ Key Features

-   **Concurrent Multi-AI Processing**: Maximizes processing speed by distributing tasks to all AI models specified in `ai_models.txt` simultaneously.
-   **Prompt-Driven Workflow**: Freely design and control the entire workflowâ€”analysis, collaboration, output formats, etc.â€”with a single Markdown file in the `prompts/` folder, requiring no code changes.
-   **Structured Data Collaboration**: Enables more stable and accurate collaboration by allowing AIs to reference structured JSON data from previous steps, a significant improvement over plain text. (Utilizes the `#other_ai_info` tag).
-   **Multimodal Input Support**: Directly pass images, PDFs, and code files to the AI for analysis using `#img`, `#pdf`, and `#code` tags within your prompt files.
-   **Live Log Monitoring**: Separately monitor the real-time progress of each model, including its reasoning process, through dedicated log files.

## ğŸ’¾ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/Your-Username/AI-Forge.git
cd AI-Forge
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Set Up Environment Variables

Copy the `.env.example` file to create a `.env` file.

```bash
cp .env.example .env
```

Open the newly created `.env` file and enter your OpenRouter API key.

```sh
# .env
OPENROUTER_API_KEY="sk-or-v1-..."
```

### 4. Configure AI Models

Open `ai_models.txt` and list the model IDs you want to use, one per line (e.g., `google/gemini-flash-1.5`).

## ğŸš€ Usage & Example

### Basic Execution

Run the following command in your terminal. You will be guided through an interactive mode to select the language and prompt.

```bash
python main.py
```

### Running a Specific Prompt

You can immediately execute a specific prompt file using the `--lang` and `--prompt` options.

```bash
# Run the research.md prompt in English
python main.py --lang en --prompt research_en.md
```

### Designing a Prompt File (Example: `prompts/research.md`)

All operations of this framework are controlled by `.md` files in the `prompts/` directory. Every prompt file must follow these rules:

-   **`## project name ##`**: A unique name for the task. It **must be the first section in the file** as it's used for the output folder name.
-   **`## system prompt ##`**: A common set of instructions (role, tone, etc.) applied to all AI models.
-   **`## promptN: [Description] ##`**: Defines a sequential step in the workflow. `N` is a number indicating the execution order.

```markdown
## project name ##
My Awesome Project

## system prompt ##
You are a top-tier analyst.

## prompt1: [Step 1: Information Gathering] ##
# reasoning
# img: path/to/your/image.jpg
# pdf: path/to/your/document.pdf
# code: path/to/your/code.py
[Detailed instructions for the prompt...]

## prompt2: [Step 2: Cross-Validation] ##
# other_ai_info
[Detailed instructions for the prompt...]
```

#### **Option Tag Details**

-   `# reasoning`: Logs the AI's thought process to a file, making debugging easier.
-   `# other_ai_info`: Allows the current AI (`prompt2`) to reference the responses generated by other AIs in the previous step (`prompt1`).
-   `# img: [path]`, `# pdf: [path]`, `# code: [path]`: Attaches the specified file to the prompt. Both local paths and URLs are supported.

## ğŸ› ï¸ Dependencies & Requirements

-   Python 3.8 or higher
-   Key Libraries: `openai`, `aiohttp`, `python-dotenv`, `tenacity` (see `requirements.txt` for details).

## â“ Troubleshooting (FAQ)

-   **Q: I'm getting an `OPENROUTER_API_KEY not found` error.**
    -   A: Please ensure that a `.env` file exists in the project's root directory and that `OPENROUTER_API_KEY` is correctly entered within it.
-   **Q: I get a `File not found` error for my prompt file.**
    -   A: Make sure the prompt file you are trying to run is located inside the `prompts/` directory.
-   **Q: An AI fails to generate a response or returns an error.**
    -   A: Check if the model ID in `ai_models.txt` is correct and that the model is currently available on OpenRouter.

---

### `DEV.md`

# AI-Forge Developer Documentation

This document provides an overview of the AI-Forge architecture, its design decisions, and a guide for future extensions.

## 1. Architecture Overview

AI-Forge adopts a modular architecture designed according to the **Separation of Concerns (SoC)** principle. Each component has a clear Single Responsibility (SRP), ensuring system stability, testability, and scalability.

-   **Separation of Config and Context**:
    -   `Config`: Immutable, pre-execution settings (API key, model list).
    -   `ProjectContext`: Mutable state generated during workflow execution (project name, output path).
-   **Separation of Engine and Services**:
    -   `WorkflowEngine`: The central orchestrator that directs the entire workflow.
    -   `Services`: Independent services that perform specific tasks (API communication, file handling, result persistence).

 <!-- Replace with actual diagram URL -->

## 2. Directory Structure

```
.
â”œâ”€â”€ config/       # Manages environment configuration and constants
â”œâ”€â”€ core/         # Core application logic (engine, data models)
â”œâ”€â”€ services/     # Handles external service integrations and specific utilities
â”œâ”€â”€ utils/        # General-purpose utilities like logging
â”œâ”€â”€ prompts/      # Stores .md files that define workflows
â””â”€â”€ projects/     # Where results generated by the AIs are saved
```

## 3. Core Component Details

### `core/engine.py` - WorkflowEngine

-   **Role**: The central control tower orchestrating the entire workflow execution.
-   **Key Responsibilities**:
    -   Initializing configuration and services.
    -   Parsing prompt files and managing the execution sequence.
    -   Creating and running parallel tasks for each AI client.
    -   Aggregating results and passing them to the next stage.
-   **Code Snippet**:
    ```python
    # core/engine.py
    class WorkflowEngine:
        async def run(self):
            await self._initialize_project()
            self._print_startup_info()
            await self._execute_workflow()
            self._print_completion_info()

        async def _execute_single_prompt(self, prompt: Prompt, is_last: bool):
            tasks = [
                self._process_model_task(client, prompt, is_last)
                for client in self.ai_clients.values()
            ]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            # ... process results
    ```

### `services/ai_client.py` - AIModelClient

-   **Role**: Dedicated to handling all communication between a single AI model and the OpenRouter API.
-   **Key Responsibilities**:
    -   Creating API request messages (including system prompt and history).
    -   Processing API streaming responses.
    -   Managing conversation history.
-   **Code Snippet**:
    ```python
    # services/ai_client.py
    class AIModelClient:
        async def get_response_stream(self, content: Any, use_reasoning: bool) -> AsyncGenerator[str, None]:
            # ... API request and stream yielding logic
    ```

### `services/result_handler.py` - ResultHandler

-   **Role**: Manages all file Input/Output (I/O) operations.
-   **Key Responsibilities**:
    -   Creating and cleaning output directories.
    -   Saving final and intermediate result files.
    -   Creating and appending content to live log files.
-   **Code Snippet**:
    ```python
    # services/result_handler.py
    class ResultHandler:
        def save_result(self, prompt_id: int, response: ModelResponse, is_final: bool):
            # ... logic to save result file
        
        def log_stream_chunk(self, model_nickname: str, chunk: str):
            # ... append stream chunk to log file
    ```

## 4. Design Decisions and Trade-offs

-   **Why This Architecture?**
    -   The initial version concentrated too many responsibilities (API calls, file I/O, state management) into a single `Orchestrator` class. This led to **High Coupling** and **Low Cohesion**, creating a high risk that small changes could have system-wide effects.
    -   The refactored architecture isolates each class to a single, clear responsibility, maximizing **stability** and **maintainability**. For example, `AIModelClient` now only concerns itself with API communication; changes to the file saving logic will not require modifying `AIModelClient`.

-   **Alternatives Considered**:
    -   **Maintaining a Single `Orchestrator` Class**: While faster to implement initially, this approach was rejected because it would lead to soaring long-term maintenance costs and a higher likelihood of bugs.
    -   **Implementing a Circuit Breaker Pattern**: Considered for enhancing API stability, but the current retry logic using the `tenacity` library was deemed sufficient for the use case. This decision was made to avoid over-engineering.

-   **Key Decision: Structured Data Pipeline**
    -   We designed the system to pass structured JSON data via the `PromptResult` data class for AI collaboration, instead of just plain text. This was a critical design choice that dramatically reduces the chance of misinterpretation by AIs, thereby enhancing the **stability** of the entire workflow.

## 5. Refactoring History

-   **Initial Version**: A monolithic structure where a single `Orchestrator` class handled most of the logic.
-   **First Refactoring (Responsibility Separation)**: Applied the SRP by splitting the `Orchestrator`'s responsibilities into `WorkflowEngine`, `ResultHandler`, and `ProjectContext`.
-   **Second Refactoring (Data Pipeline Enhancement)**: Introduced the `PromptResult` model to enable the use of JSON data in AI collaboration.

## 6. External Libraries

-   `openai`: The client for communicating with OpenRouter's API. (Alternative: direct implementation using `httpx`).
-   `aiohttp`: Used for asynchronously fetching model metadata.
-   `python-dotenv`: Loads environment variables from `.env` files.
-   `tenacity`: Simplifies the implementation of retries with exponential backoff for failed API requests.

## 7. Future Extension Guide

-   **Adding a New Service (e.g., Slack notifications)**
    1.  Create a `services/notification_service.py` file.
    2.  Add a call to your notification service at the end of the `WorkflowEngine.run` method.
-   **Adding a New Prompt File Command (e.g., `#db_query`)**
    1.  Add the new command to the `FILE_COMMANDS` dictionary in `config/constants.py`.
    2.  Add the relevant logic to the `_extract_attachments` method in `services/prompt_parser.py`.
    3.  Implement a method like `_handle_db_query` in `services/file_handler.py` to process the command.